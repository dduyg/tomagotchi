# Pipeline Files

```yaml
# File: contracts/user_signups.yaml
contract:
  name: user_signups
  version: 1.3.0
  owner: marketing-data-team@company.com
  domain: user_acquisition
  description: >
    Daily export of new user signups from the application database.
    Used by analytics and ML teams for retention and growth metrics.

  schema:
    fields:
      - name: user_id
        type: string
        description: Unique ID of the user.
        constraints:
          required: true
          unique: true

      - name: signup_timestamp
        type: timestamp
        description: UTC time of signup event.
        constraints:
          required: true
          not_null: true

      - name: country
        type: string
        description: ISO 3166-1 alpha-2 country code.
        constraints:
          allowed_values: ["US", "CA", "GB", "IN", "DE", "FR", "OTHER"]

      - name: referral_source
        type: string
        description: How the user found the product.
        constraints:
          nullable: true

      - name: is_premium
        type: boolean
        description: Whether the user subscribed to a paid plan.
        default: false

  data_quality_rules:
    - name: no_null_ids
      condition: "user_id IS NOT NULL"
      severity: error

    - name: valid_country_codes
      condition: "country IN ('US','CA','GB','IN','DE','FR','OTHER')"
      severity: warning

    - name: signup_date_recent
      condition: "signup_timestamp >= CURRENT_DATE - INTERVAL '7 days'"
      severity: info

  slas:
    freshness: "Data must be available by 02:00 UTC daily"
    completeness: "â‰¥99% of records expected vs previous 7-day rolling average"
    latency: "Under 30 min for pipeline completion"

  change_policy:
    breaking_changes:
      - removing or renaming columns
      - changing data types
    notification:
      channels: ["#data-contracts", "email:analytics-team@company.com"]
      notice_period_days: 7
```

```python
# validate_user_signups.py
from great_expectations.dataset import PandasDataset
import pandas as pd

class UserSignupsDataset(PandasDataset):
    def validate_schema(self):
        self.expect_column_to_exist("user_id")
        self.expect_column_values_to_not_be_null("user_id")
        self.expect_column_to_exist("signup_timestamp")
        self.expect_column_values_to_not_be_null("signup_timestamp")
        self.expect_column_values_to_be_in_set(
            "country", ["US", "CA", "GB", "IN", "DE", "FR", "OTHER"]
        )

def run_validation(file_path):
    df = pd.read_parquet(file_path)
    dataset = UserSignupsDataset(df)
    results = dataset.validate(expectation_suite_name="user_signups_suite")
    if not results["success"]:
        raise ValueError("Data contract validation failed!")
```

```python
# airflow_dag_user_signups.py
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta
from validate_user_signups import run_validation

default_args = {
    "owner": "data-team",
    "start_date": datetime(2025, 10, 1),
    "retries": 1,
    "retry_delay": timedelta(minutes=5),
}

with DAG(
    "user_signups_pipeline",
    default_args=default_args,
    schedule_interval="@daily",
    catchup=False,
) as dag:

    extract = PythonOperator(
        task_id="extract_data",
        python_callable=lambda: print("Extracting user signups..."),
    )

    validate = PythonOperator(
        task_id="validate_contract",
        python_callable=run_validation,
        op_args=["/data/staging/user_signups.parquet"],
    )

    load_to_warehouse = PythonOperator(
        task_id="load_to_warehouse",
        python_callable=lambda: print("Loading data to Snowflake..."),
    )

    extract >> validate >> load_to_warehouse
```

```yaml
# models/staging/user_signups.yml
version: 2

models:
  - name: stg_user_signups
    description: "Validated user signup data"
    columns:
      - name: user_id
        tests:
          - not_null
          - unique
      - name: country
        tests:
          - accepted_values:
              values: ['US', 'CA', 'GB', 'IN', 'DE', 'FR', 'OTHER']
```